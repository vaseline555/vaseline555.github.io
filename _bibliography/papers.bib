@inproceedings{hahn22superfed,
  bibtex_show={true},
  abbr={KDD},
  additional_info={This work is done at [Kakao Enterprise](https://kakaoenterprise.github.io/papers/sigkdd-federated-learning) through AI Research Internship.},
  title={Connecting low-loss subspace for personalized federated learning},
  author={Hahn, Seok-Ju and Jeong, Minwoo and Lee, Junghye},
  booktitle={Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={505--515},
  year={2022},
  abstract={Due to the curse of statistical heterogeneity across clients, adopting a personalized federated learning method has become an essential choice for the successful deployment of federated learning-based services. Among diverse branches of personalization techniques, a model mixture-based personalization method is preferred as each client has their own personalized model as a result of federated learning. It usually requires a local model and a federated model, but this approach is either limited to partial parameter exchange or requires additional local updates, each of which is helpless to novel clients and burdensome to the client's computational capacity. As the existence of a connected subspace containing diverse low-loss solutions between two or more independent deep networks has been discovered, we combined this interesting property with the model mixture-based personalized federated learning method for improved performance of personalization. We proposed SuPerFed, a personalized federated learning method that induces an explicit connection between the optima of the local and the federated model in weight space for boosting each other. Through extensive experiments on several benchmark datasets, we demonstrated that our method achieves consistent gains in both personalization performance and robustness to problematic scenarios possible in realistic services.},
  html={https://dl.acm.org/doi/abs/10.1145/3534678.3539254},
  pdf={https://arxiv.org/pdf/2109.07628},
  video={https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3534678.3539254&file=KDD22-fp0360..mp4},
  code={https://github.com/vaseline555/superfed},
  selected={true}
}

@article{hahn22t2d,
  bibtex_show={true},
  abbr={EBIOM},
  additional_info={Seok-Ju and Suhyeon contributed equally to this work.},
  title={Prediction of type 2 diabetes using genome-wide polygenic risk score and metabolic profiles: a machine learning analysis of population-based 10-year prospective cohort study},
  author={Hahn, Seok-Ju and Kim, Suhyeon and Choi, Young Sik and Lee, Junghye and Kang, Jihun},
  journal={EBioMedicine},
  volume={86},
  year={2022},
  publisher={Elsevier},
  abstract={Background: Previous work on predicting type 2 diabetes by integrating clinical and genetic factors has mostly focused on the Western population. In this study, we use genome-wide polygenic risk score (gPRS) and serum metabolite data for type 2 diabetes risk prediction in the Asian population.
    Methods: Data of 1425 participants from the Korean Genome and Epidemiology Study (KoGES) Ansan-Ansung cohort were used in this study. For gPRS analysis, genotypic and clinical information from KoGES health examinee (n = 58,701) and KoGES cardiovascular disease association (n = 8105) sub-cohorts were included. Linkage disequilibrium analysis identified 239,062 genetic variants that were used to determine the gPRS, while the metabolites were selected using the Boruta algorithm. We used bootstrapped cross-validation to evaluate logistic regression and random forest (RF)-based machine learning models. Finally, associations of gPRS and selected metabolites with the values of homeostatic model assessment of beta-cell function (HOMA-B) and insulin resistance (HOMA-IR) were further estimated.
    Findings: During the follow-up period (8.3 Â± 2.8 years), 331 participants (23.2%) were diagnosed with type 2 diabetes. The areas under the curves of the RF-based models were 0.844, 0.876, and 0.883 for the model using only demographic and clinical factors, model including the gPRS, and model with both gPRS and metabolites, respectively. Incorporation of additional parameters in the latter two models improved the classification by 11.7% and 4.2% respectively. While gPRS was significantly associated with HOMA-B value, most metabolites had a significant association with HOMA-IR value.
    Interpretation: Incorporating both gPRS and metabolite data led to enhanced type 2 diabetes risk prediction by capturing distinct etiologies of type 2 diabetes development. An RF-based model using clinical factors, gPRS, and metabolites predicted type 2 diabetes risk more accurately than the logistic regression-based model.},
  html={https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(22)00565-5/fulltext},
  pdf={https://www.thelancet.com/action/showPdf?pii=S2352-3964%2822%2900565-5},
  code={https://github.com/vaseline555/T2D-Predictive-Modeling-for-Korean-with-gPRS-and-Metabolites},
  selected={true}
}

@article{hahn24aaggff,
  bibtex_show={true},
  abbr={ICML},
  title={Pursuing Overall Welfare in Federated Learning through Sequential Decision Making},
  author={Hahn, Seok-Ju and Kim, Gi-Soo and Lee, Junghye},
  journal={arXiv preprint arXiv:2405.20821},
  year={2024},
  abstract={In traditional federated learning, a single global model cannot perform equally well for all clients. Therefore, the need to achieve the client-level fairness in federated system has been emphasized, which can be realized by modifying the static aggregation scheme for updating the global model to an adaptive one, in response to the local signals of the participating clients. Our work reveals that existing fairness-aware aggregation strategies can be unified into an online convex optimization framework, in other words, a central server's sequential decision making process. To enhance the decision making capability, we propose simple and intuitive improvements for suboptimal designs within existing methods, presenting AAggFF. Considering practical requirements, we further subdivide our method tailored for the cross-device and the cross-silo settings, respectively. Theoretical analyses guarantee sublinear regret upper bounds for both settings: $\mathcal{O}(\sqrt{T\log{K}})$ for the cross-device setting, and $\mathcal{O}(K\log{T})$ for the cross-silo setting, with $K$ clients and $T$ federation rounds. Extensive experiments demonstrate that the federated system equipped with AAggFF achieves better degree of client-level fairness than existing methods in both practical settings.},
  html={},
  pdf={https://arxiv.org/pdf/2405.20821},
  video={},
  code={https://github.com/vaseline555/AAggFF},
  selected={true}
}

@article{kim24cafo,
  bibtex_show={true},
  abbr={KDD},
  additional_info={Jaeho, Seok-Ju and Yoontae contributed equally to this work.},
  title={CAFO: Feature-Centric Explanation on Time Series Classification},
  author={Kim, Jaeho and Hahn, Seok-Ju and Hwang, Yoontae and Lee, Junghye and Lee, Seulki},
  journal={arXiv preprint arXiv:2406.01833},
  year={2024},
  abstract={In multivariate time series (MTS) classification, finding the important features (e.g., sensors) for model performance is crucial yet challenging due to the complex, high-dimensional nature of MTS data, intricate temporal dynamics, and the necessity for domain-specific interpretations. Current explanation methods for MTS mostly focus on time-centric explanations, apt for pinpointing important time periods but less effective in identifying key features. This limitation underscores the pressing need for a feature-centric approach, a vital yet often overlooked perspective that complements time-centric analysis. To bridge this gap, our study introduces a novel feature-centric explanation and evaluation framework for MTS, named CAFO (Channel Attention and Feature Orthgonalization). CAFO employs a convolution-based approach with channel attention mechanisms, incorporating a depth-wise separable channel attention module (DepCA) and a QR decomposition-based loss for promoting feature-wise orthogonality. We demonstrate that this orthogonalization enhances the separability of attention distributions, thereby refining and stabilizing the ranking of feature importance. This improvement in feature-wise ranking enhances our understanding of feature explainability in MTS. Furthermore, we develop metrics to evaluate global and class-specific feature importance. Our framework's efficacy is validated through extensive empirical analyses on two major public benchmarks and real-world datasets, both synthetic and self-collected, specifically designed to highlight class-wise discriminative features. The results confirm CAFO's robustness and informative capacity in assessing feature importance in MTS classification tasks. This study not only advances the understanding of feature-centric explanations in MTS but also sets a foundation for future explorations in feature-centric explanations.},
  html={},
  pdf={https://arxiv.org/pdf/2406.01833},
  video={},
  code={https://github.com/eai-lab/CAFO}
}
